{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "import numpy as np\n",
    "from ops import *\n",
    "from utils import *\n",
    "import os\n",
    "import time\n",
    "from glob import glob\n",
    "from scipy.misc import imsave as ims\n",
    "from data_providers import *\n",
    "import scipy as sp\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "%pylab inline\n",
    "import datetime\n",
    "import sys\n",
    "import json\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size':32,\n",
    "    'image_dim':128*128*3,\n",
    "    'c':3,\n",
    "    'h':64,\n",
    "    'w':64,\n",
    "    'im_channels':3,\n",
    "    'im_height':64,\n",
    "    'im_width':64,\n",
    "    'latent_code':11,\n",
    "    'latent_noise_dim':100,\n",
    "    'color_dim':50\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x,eps, reuse=False):\n",
    "    with tf.variable_scope(\"enc\") as scope:\n",
    "        if reuse:\n",
    "                scope.reuse_variables()\n",
    "        gf_dim=64\n",
    "        h=64\n",
    "        w=64\n",
    "        s2, s4, s8, s16 = int(gf_dim/2), int(gf_dim/4), int(gf_dim/8), int(gf_dim/16)\n",
    "        x2 = dense(x, params['latent_code'], gf_dim*8*s16*s16, scope='g_h0_lin')\n",
    "        \n",
    "        mu = tf.reshape(slim.fully_connected(eps,gf_dim*8*s16*s16),[-1, s16, s16, gf_dim * 8])\n",
    "        sig = tf.reshape(slim.fully_connected(eps,gf_dim*8*s16*s16),[-1, s16, s16, gf_dim * 8])\n",
    "        h0 = tf.contrib.layers.instance_norm(tf.reshape(x2, [-1, s16, s16, gf_dim * 8]),center=False,scale=False)\n",
    "        h0 = tf.nn.relu(sig*h0 + mu)\n",
    "        \n",
    "        mu = tf.reshape(slim.fully_connected(eps,gf_dim*4*s8*s8),[batchsize, s8, s8, gf_dim*4])\n",
    "        sig = tf.reshape(slim.fully_connected(eps,gf_dim*4*s8*s8),[batchsize, s8, s8, gf_dim*4])\n",
    "        h1 = tf.contrib.layers.instance_norm(conv_transpose(h0, [batchsize, s8, s8, gf_dim*4], \"g_h1\"),center=False,scale=False)\n",
    "        h1 = tf.nn.relu(sig*h1 + mu)\n",
    "        \n",
    "        mu = tf.reshape(slim.fully_connected(eps,gf_dim*2*s4*s4),[batchsize, s4, s4, gf_dim*2])\n",
    "        sig = tf.reshape(slim.fully_connected(eps,gf_dim*2*s4*s4),[batchsize, s4, s4, gf_dim*2])\n",
    "        h2 = tf.contrib.layers.instance_norm(conv_transpose(h1, [batchsize, s4, s4, gf_dim*2], \"g_h2\"),center=False,scale=False)\n",
    "        h2 = tf.nn.relu(sig*h2 + mu)\n",
    "        \n",
    "        mu = tf.reshape(slim.fully_connected(eps,gf_dim*1*s2*s2),[batchsize, s2, s2, gf_dim*1])\n",
    "        sig = tf.reshape(slim.fully_connected(eps,gf_dim*1*s2*s2),[batchsize, s2, s2, gf_dim*1])\n",
    "        h3 = tf.contrib.layers.instance_norm(conv_transpose(h2, [batchsize, s2, s2, gf_dim*1], \"g_h3\"),center=False,scale=False)\n",
    "        h3 = tf.nn.relu(sig*h3 + mu)\n",
    "        \n",
    "        h4 = tf.nn.sigmoid(conv_transpose(h3, [batchsize, h, w, 3], \"g_h4\"))\n",
    "        \n",
    "        return h4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(image,c, reuse=False):\n",
    "    \n",
    "    with tf.variable_scope(\"disc\") as scope:\n",
    "        if reuse:\n",
    "                scope.reuse_variables()\n",
    "        df_dim=params['h']\n",
    "        h=params['h']\n",
    "        w=params['w']\n",
    "        \n",
    "        h0 = tf.concat([image, c], 3)\n",
    "        \n",
    "        h0 = lrelu(conv2d(h0, 6, df_dim, name='d_h0_conv'))\n",
    "        h1 = lrelu(tf.contrib.layers.batch_norm(conv2d(h0, df_dim, df_dim*2, name='d_h1_conv'))) #8x8x64\n",
    "        h2 = lrelu(tf.contrib.layers.batch_norm(conv2d(h1, df_dim*2, df_dim*4, name='d_h2_conv'))) #4x4x128\n",
    "        h3 = lrelu(tf.contrib.layers.batch_norm(conv2d(h2, df_dim*4, df_dim*8, name='d_h3_conv'))) #4x4x128\n",
    "        h3 = tf.reshape(h3, [batchsize, -1])\n",
    "        \n",
    "        logit = (dense(h3, 8192, 1, scope='d_mu_lin')) \n",
    "        return logit\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "def decoder(y,eps, reuse=False):\n",
    "    with tf.variable_scope(\"dec\") as scope:\n",
    "        if reuse:\n",
    "                scope.reuse_variables()\n",
    "        gf_dim=64\n",
    "        df_dim=params['h']\n",
    "        h=64\n",
    "        w=64\n",
    "        s2, s4, s8, s16 = int(gf_dim/2), int(gf_dim/4), int(gf_dim/8), int(gf_dim/16)\n",
    "        \n",
    "        #Conv\n",
    "        h0 = lrelu(conv2d(y, 3, df_dim, name='d_h0_conv'))\n",
    "        \n",
    "        mu = tf.reshape(slim.fully_connected(eps,gf_dim*2*s4*s4),[-1, s4, s4, gf_dim * 2])\n",
    "        sig = tf.reshape(slim.fully_connected(eps,gf_dim*2*s4*s4),[-1, s4, s4, gf_dim * 2])\n",
    "        h1 = tf.contrib.layers.instance_norm(conv2d(h0, df_dim, df_dim*2, name='d_h1_conv'),center=False,scale=False)\n",
    "        h1 = lrelu(sig*h1 + mu) \n",
    "        \n",
    "        mu = tf.reshape(slim.fully_connected(eps,gf_dim*4*s8*s8),[-1, s8, s8, gf_dim * 4])\n",
    "        sig = tf.reshape(slim.fully_connected(eps,gf_dim*4*s8*s8),[-1, s8, s8, gf_dim * 4])\n",
    "        h2 = tf.contrib.layers.instance_norm(conv2d(h1, df_dim*2, df_dim*4, name='d_h2_conv'),center=False,scale=False)\n",
    "        h2 = lrelu(sig*h2 + mu) \n",
    "        \n",
    "        mu = tf.reshape(slim.fully_connected(eps,gf_dim*8*s16*s16),[-1, s16, s16, gf_dim * 8])\n",
    "        sig = tf.reshape(slim.fully_connected(eps,gf_dim*8*s16*s16),[-1, s16, s16, gf_dim * 8])\n",
    "        h3 = tf.contrib.layers.instance_norm(conv2d(h2, df_dim*4, df_dim*8, name='d_h3_conv'),center=False,scale=False)\n",
    "        h3 = lrelu(sig*h3 + mu)\n",
    "        \n",
    "        h3 = tf.reshape(h3, [batchsize, -1])\n",
    "\n",
    "        y2 = dense(h3, 8192+0, gf_dim*8*s16*s16, scope='g_h0_lin')\n",
    "        \n",
    "        #Deconv\n",
    "        mu = tf.reshape(slim.fully_connected(eps,gf_dim*8*s16*s16),[-1, s16, s16, gf_dim * 8])\n",
    "        sig = tf.reshape(slim.fully_connected(eps,gf_dim*8*s16*s16),[-1, s16, s16, gf_dim * 8])\n",
    "        h0 = tf.contrib.layers.instance_norm(tf.reshape(y2, [-1, s16, s16, gf_dim * 8]),center=False,scale=False)\n",
    "        h0 = tf.nn.relu(sig*h0 + mu)\n",
    "        \n",
    "        mu = tf.reshape(slim.fully_connected(eps,gf_dim*4*s8*s8),[batchsize, s8, s8, gf_dim*4])\n",
    "        sig = tf.reshape(slim.fully_connected(eps,gf_dim*4*s8*s8),[batchsize, s8, s8, gf_dim*4])\n",
    "        h1 = tf.contrib.layers.instance_norm(conv_transpose(h0, [batchsize, s8, s8, gf_dim*4], \"g_h1\"),center=False,scale=False)\n",
    "        h1 = tf.nn.relu(sig*h1 + mu)\n",
    "        \n",
    "        mu = tf.reshape(slim.fully_connected(eps,gf_dim*2*s4*s4),[batchsize, s4, s4, gf_dim*2])\n",
    "        sig = tf.reshape(slim.fully_connected(eps,gf_dim*2*s4*s4),[batchsize, s4, s4, gf_dim*2])\n",
    "        h2 = tf.contrib.layers.instance_norm(conv_transpose(h1, [batchsize, s4, s4, gf_dim*2], \"g_h2\"),center=False,scale=False)\n",
    "        h2 = tf.nn.relu(sig*h2 + mu)\n",
    "        \n",
    "        mu = tf.reshape(slim.fully_connected(eps,gf_dim*1*s2*s2),[batchsize, s2, s2, gf_dim*1])\n",
    "        sig = tf.reshape(slim.fully_connected(eps,gf_dim*1*s2*s2),[batchsize, s2, s2, gf_dim*1])\n",
    "        h3 = tf.contrib.layers.instance_norm(conv_transpose(h2, [batchsize, s2, s2, gf_dim*1], \"g_h3\"),center=False,scale=False)\n",
    "        h3 = tf.nn.relu(sig*h3 + mu)\n",
    "        \n",
    "        h4 = tf.nn.sigmoid(conv_transpose(h3, [batchsize, h, w, 3], \"g_h4\"))\n",
    "        \n",
    "        return h4\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batchsize = params['batch_size']\n",
    "imageshape = [64, 64, 3]\n",
    "c_dim = params['latent_code']\n",
    "gf_dim = 64\n",
    "df_dim = 64\n",
    "learningrate = 0.0001\n",
    "beta1 = 0.5\n",
    "\n",
    "\n",
    "images = tf.placeholder(tf.float32, [batchsize] + imageshape, name=\"real_images\")\n",
    "c_input = tf.placeholder(tf.float32, [batchsize] + [c_dim], name=\"code\")\n",
    "eps = tf.placeholder(tf.float32, [batchsize,params['latent_noise_dim']], name=\"noise\")\n",
    "\n",
    "#Encoder\n",
    "E_enc = encoder(c_input,eps)\n",
    "\n",
    "#Decoder\n",
    "G_dec = decoder(E_enc,eps)\n",
    "\n",
    "#Discriminator \n",
    "img_logits = discriminator(images,E_enc)\n",
    "gen_logits = discriminator(G_dec,E_enc,reuse=True)\n",
    "\n",
    "#Disc Loss\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=img_logits,labels=tf.ones_like(img_logits)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gen_logits,labels=tf.zeros_like(gen_logits)))\n",
    "d_loss = (d_loss_real + d_loss_fake)/2.\n",
    "\n",
    "#Gen Loss\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gen_logits,labels=tf.ones_like(gen_logits)))\n",
    "\n",
    "#Enc Loss\n",
    "e_loss = tf.reduce_mean(metrics.mean_squared_error(images, E_enc))\n",
    "\n",
    "#Optimisation\n",
    "t_vars = tf.trainable_variables()\n",
    "g_vars = [var for var in t_vars if 'dec' in var.name]\n",
    "d_vars = [var for var in t_vars if 'disc' in var.name]\n",
    "e_vars = [var for var in t_vars if 'enc' in var.name]\n",
    "\n",
    "optim_e = tf.train.AdamOptimizer(learningrate, beta1=beta1).minimize(e_loss, var_list=e_vars)\n",
    "optim_g = tf.train.AdamOptimizer(learningrate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "optim_d = tf.train.AdamOptimizer(learningrate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    tf.Session.close(sess)\n",
    "except:\n",
    "    print(\"nothing to close\")\n",
    "    \n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "tf.initialize_all_variables().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = numpy.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "TRAIN_STOP=100000\n",
    "data = json.load(open('../img_store'))[:TRAIN_STOP]\n",
    "c_store=np.load('../c_store_full')[:TRAIN_STOP]\n",
    "gc.collect()\n",
    "\n",
    "TRAIN_STOP = 100000\n",
    "\n",
    "train_data64=np.asarray(data[:TRAIN_STOP])\n",
    "train_c_store = c_store[:TRAIN_STOP]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import *\n",
    "\n",
    "for epoch in tqdm_notebook(xrange(15)):\n",
    "    \n",
    "    train_data64, train_c_store = unison_shuffled_copies(train_data64, train_c_store)\n",
    "    gc.collect()\n",
    "    \n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    batch_idxs = len(train_data64) // params['batch_size']\n",
    "\n",
    "    \n",
    "    for idx in tqdm_notebook(range(batch_idxs)):\n",
    "        \n",
    "        batch_files = train_data64[idx*params['batch_size']:(idx+1)*params['batch_size']]\n",
    "        c_batch = np.asarray(train_c_store[idx*params['batch_size']:(idx+1)*params['batch_size']])\n",
    "\n",
    "        eps_batch = np.random.normal(0,1,[params['batch_size'], params['latent_noise_dim']]).astype(np.float32)\n",
    "        \n",
    "        batch_img = [\n",
    "          get_image(batch_file,\n",
    "                    input_height=178,\n",
    "                    input_width=218,\n",
    "                    resize_height=64,\n",
    "                    resize_width=64,\n",
    "                    is_crop=False)/255. for batch_file in batch_files]\n",
    "\n",
    "        batch_img = np.array(batch_img).astype(np.float32)\n",
    "        \n",
    "        # Train\n",
    "        feed_dict = {c_input:c_batch,images:batch_img, \n",
    "                     eps:eps_batch}\n",
    "        if epoch < 0:\n",
    "            _ = sess.run([optim_e],\n",
    "                                feed_dict=feed_dict)        \n",
    "        else:\n",
    "            _ = sess.run([optim_g,optim_d],\n",
    "                                feed_dict=feed_dict)\n",
    "           \n",
    "   \n",
    "        if idx % 500 == 0:\n",
    "\n",
    "            print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, \" % (epoch, idx, batch_idxs, time.time() - start_time,))\n",
    "    \n",
    "            E_enc_data, G_dec_data = sess.run([E_enc,G_dec],feed_dict = feed_dict)\n",
    "            sdata = E_enc_data[:5]\n",
    "            sdata = np.clip(sdata,0,1)\n",
    "            sdata = np.expand_dims(sdata,0)\n",
    "            img = merge(sdata[0],[1,5])\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "            \n",
    "            sdata = G_dec_data[:5]\n",
    "            sdata = np.clip(sdata,0,1)\n",
    "            sdata = np.expand_dims(sdata,0)\n",
    "            img = merge(sdata[0],[1,5])\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "           \n",
    "            sdata = batch_img[:5]\n",
    "            sdata = np.clip(sdata,0,1)\n",
    "            sdata = np.expand_dims(sdata,0)\n",
    "            img = merge(sdata[0],[1,5])\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.imshow(img)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Get traversal gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "c_batch = np.asarray(train_c_store[idx*params['batch_size']:(idx+1)*params['batch_size']])\n",
    "c_batch_ = copy(c_batch)\n",
    "\n",
    "lb=0\n",
    "ub=0\n",
    "latent_dim = 2\n",
    "lb = np.min(train_c_store[:,latent_dim])\n",
    "ub = np.max(train_c_store[:,latent_dim])\n",
    "c_batch_ = np.asarray([c_batch[2] for _ in range(32)])\n",
    "c_batch_[:,latent_dim] = np.linspace(lb, ub, params['batch_size'])\n",
    "eps_test = np.random.normal(0,1,[1, params['latent_noise_dim']])\n",
    "latent_noise = eps_test.repeat(32, axis=0)\n",
    "images_ = []\n",
    "\n",
    "feed_dict = {c_input:c_batch_, eps:latent_noise,images: batch_img,}\n",
    "G_dec_data = sess.run(G_dec,feed_dict = feed_dict)\n",
    "\n",
    "#Visualise\n",
    "for val in range(32):\n",
    "    sdata = G_dec_data[val:val+1]\n",
    "    sdata = np.clip(sdata,0,1)\n",
    "    sdata = np.expand_dims(sdata,0)\n",
    "    img = merge(sdata[0],[1,1])\n",
    "    images_.append(img)\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "imageio.mimsave('traversal.gif', images_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
